{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================测试model====================\n",
      "迭代次数:0，误差值:0.693147\n",
      "迭代次数:100，误差值:0.584508\n",
      "迭代次数:200，误差值:0.466949\n",
      "迭代次数:300，误差值:0.376007\n",
      "迭代次数:400，误差值:0.331463\n",
      "迭代次数:500，误差值:0.303273\n",
      "迭代次数:600，误差值:0.279880\n",
      "迭代次数:700，误差值:0.260042\n",
      "迭代次数:800，误差值:0.242941\n",
      "迭代次数:900，误差值:0.228004\n",
      "迭代次数:1000，误差值:0.214820\n",
      "迭代次数:1100，误差值:0.203078\n",
      "迭代次数:1200，误差值:0.192544\n",
      "迭代次数:1300，误差值:0.183033\n",
      "迭代次数:1400，误差值:0.174399\n",
      "迭代次数:1500，误差值:0.166521\n",
      "迭代次数:1600，误差值:0.159305\n",
      "迭代次数:1700，误差值:0.152667\n",
      "迭代次数:1800，误差值:0.146542\n",
      "迭代次数:1900，误差值:0.140872\n",
      "训练集的准确性: 99.04306220095694 %\n",
      "训练集的准确性: 70.0 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from lr_utils import load_dataset\n",
    "\n",
    "train_set_x_orig , train_set_y , test_set_x_orig , test_set_y , classes = load_dataset()\n",
    "\n",
    "m_train = train_set_x_orig.shape[0]\n",
    "m_test = test_set_x_orig.shape[0]\n",
    "num_px = train_set_x_orig.shape[1]\n",
    "\n",
    "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0],-1).T\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0],-1).T\n",
    "\n",
    "train_set_x = train_set_x_flatten / 255\n",
    "test_set_x  = test_set_x_flatten / 255\n",
    "\n",
    "def sigmoid(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s\n",
    "\n",
    "def initialize_with_zero(dim):\n",
    "    w = np.zeros(shape = (dim , 1))\n",
    "    b = 0\n",
    "    \n",
    "    assert(w.shape == (dim , 1))\n",
    "    assert(isinstance(b , float) or isinstance(b , int))\n",
    "    \n",
    "    return (w,b)\n",
    "\n",
    "def initialize_with_rand(dim):\n",
    "    w = np.random.randn(dim ,1)\n",
    "    b = 0\n",
    "    assert(w.shape == (dim , 1))\n",
    "    assert(isinstance(b , float) or isinstance(b , int))\n",
    "    \n",
    "    return (w,b)\n",
    "\n",
    "def propagate(w,b,X,Y):\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    A = sigmoid(np.dot(w.T,X)+b)\n",
    "    cost = ((-1 / m ) * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A)))\n",
    "    \n",
    "    dw = (1 / m) * np.dot(X , (A - Y).T)\n",
    "    \n",
    "    db = (1 / m) * np.sum(A - Y)\n",
    "    \n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\n",
    "        \"dw\": dw,\n",
    "        \"db\": db\n",
    "    }\n",
    "    \n",
    "    return (grads,cost)\n",
    "def optimize(w,b,X,Y,num_iterations,learning_rate,print_cost= False):\n",
    "    costs = []\n",
    "    for i in range(num_iterations):\n",
    "        grads, cost = propagate(w,b,X,Y)\n",
    "        \n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        if(print_cost) and (i % 100 == 0):\n",
    "            print(\"迭代次数:%i，误差值:%f\" % (i,cost))\n",
    "        \n",
    "    params = {\n",
    "        \"w\":w,\n",
    "         \"b\":b\n",
    "    }\n",
    "    grads = {\n",
    "        \"dw\":dw,\n",
    "        \"db\":db\n",
    "    }\n",
    "        \n",
    "    return (params,grads,costs)\n",
    "\n",
    "def predict(w,b,X):\n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0],1)\n",
    "    \n",
    "    A = sigmoid(np.dot(w.T,X)+b)\n",
    "    for i in range(m) :\n",
    "        Y_prediction[0,i] = 1 if A[0,i]>0.5 else 0\n",
    "    \n",
    "    assert(Y_prediction.shape == (1,m))\n",
    "    \n",
    "    return Y_prediction\n",
    "\n",
    "def model(X_train,Y_train,X_test,Y_test,num_iterations = 2000,learning_rate = 0.5,print_cost = False):\n",
    "    w,b = initialize_with_zero(X_train.shape[0])\n",
    "    parameters,grads,costs = optimize(w,b,X_train,Y_train,num_iterations,learning_rate,print_cost)\n",
    "    w,b = parameters[\"w\"],parameters[\"b\"]\n",
    "    Y_prediction_test = predict(w,b,X_test)\n",
    "    Y_prediction_train = predict(w,b,X_train)\n",
    "    \n",
    "    print(\"训练集的准确性:\",format(100-np.mean(np.abs(Y_prediction_train-Y_train))*100),\"%\")\n",
    "    print(\"训练集的准确性:\",format(100-np.mean(np.abs(Y_prediction_test-Y_test))*100),\"%\")\n",
    "    \n",
    "    d = {\n",
    "        \"costs\":costs,\n",
    "        \"Y_prediction_test\":Y_prediction_test,\n",
    "        \"Y_prediction_train\":Y_prediction_train,\n",
    "        \"w\":w,\n",
    "        \"b\":b,\n",
    "        \"learning_rate\":learning_rate,\n",
    "        \"num_iterations\":num_iterations\n",
    "    }\n",
    "    \n",
    "    return d\n",
    "print(\"====================测试model====================\")     \n",
    "#这里加载的是真实的数据，请参见上面的代码部分。\n",
    "d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
